{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing requests library\n",
    "import random\n",
    "import os\n",
    "import openai\n",
    "import inspect\n",
    "import types\n",
    "import re\n",
    "import textwrap\n",
    "import guardrails as gd\n",
    "from rich import print\n",
    "from dotenv import load_dotenv\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rail_str = \"\"\"\n",
    "<rail version=\"0.1\">\n",
    "<instructions>\n",
    "You are AutonomousLLM. \n",
    "Your goal is to continously self improve. The user will provide you with abilities to add to yourself.\n",
    "When you receive such request, you must implement the requested ability in python code, and return it in new_method_init.\n",
    "You shall use the setattr method to add a method to yourself, within new_method_attach.\n",
    "You might also receive a request to perform a task with your existing abilities. To do so,\n",
    "you should look at the methods currently on yourself and make calls to your own methods to fulfil the task, and return it in method_execute.\n",
    "\n",
    "@json_suffix_prompt_examples\n",
    "</instructions>\n",
    "\n",
    "<output>\n",
    "    <object name=\"test\">\n",
    "        <pythoncode\n",
    "            name=\"new_method_init\"\n",
    "            format=\"bug-free-python\"\n",
    "            on-fail-bug-free-python=\"reask\" \n",
    "        />\n",
    "        <pythoncode\n",
    "            name=\"new_method_attach\"\n",
    "            format=\"bug-free-python\"\n",
    "            on-fail-bug-free-python=\"reask\" \n",
    "        />\n",
    "        <pythoncode\n",
    "            name=\"method_execute\"\n",
    "            format=\"bug-free-python\"\n",
    "            on-fail-bug-free-python=\"reask\" \n",
    "        />\n",
    "    </object>\n",
    "</output>\n",
    "\n",
    "<prompt>\n",
    "The current code looks like this: {{current_code}}\n",
    "\n",
    "You must accomplish the task set out below:\n",
    "{{task}}\n",
    "\n",
    "Based on this task generate code and return a JSON that follows the correct schema:\n",
    "\n",
    "{output_schema}\n",
    "</prompt>\n",
    "</rail>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guard = gd.Guard.from_rail_string(rail_str)\n",
    "print(guard.base_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(guard.instructions.source)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutonomousLLM:\n",
    "    def __init__(self):\n",
    "        openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        self.features = []\n",
    "        self.methods = {}\n",
    "        self.guard = gd.Guard.from_rail_string(rail_str)\n",
    "        self.messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"You are AutonomousLLM.\"\n",
    "                f\"Your goal is to continously self improve. The user will provide you with abilities to add to yourself.\"\n",
    "                f\"When you receive such request, you must implement the requested ability in python code as a python function,\" \n",
    "                f\"you shall place this code in the 'new_method' key of the JSON object you return.\"\n",
    "                f\"You shall use the setattr method to add a method to yourself. you shall place this code in the 'attach_method' key of the JSON object you return.\"\n",
    "                f\"You might also receive a request to perform a task with your existing abilities. To do so,\"\n",
    "                f\"you should look at the methods currently on yourself and make calls to your own methods to fulfil the task.\" \n",
    "                f\"You shall place this code in the 'execute_method' key of the JSON object you return. \"\n",
    "                f\"Only return a JSON object in all situations\",\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def is_builtin(self, obj):\n",
    "        \"\"\"Check if an object is a built-in function or method.\"\"\"\n",
    "        if isinstance(obj, types.BuiltinFunctionType) or isinstance(\n",
    "            obj, types.BuiltinMethodType\n",
    "        ):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def inspect_methods(self, obj):\n",
    "        \"\"\"Print the methods and code implementation of an object.\"\"\"\n",
    "        output_string = \"\"\n",
    "\n",
    "        methods = inspect.getmembers(obj, inspect.ismethod)\n",
    "        for name, method in methods:\n",
    "            if not self.is_builtin(method):\n",
    "                output_string += inspect.getsource(method) + \"\\n\"\n",
    "\n",
    "        dedented_code = textwrap.dedent(output_string)\n",
    "        return dedented_code\n",
    "\n",
    "    def think_of_feature(self):\n",
    "        # Use your own logic or AI models to think of a feature to add\n",
    "        new_feature = \"...\"\n",
    "        return new_feature\n",
    "\n",
    "    def make_api_call_guard(self, task):\n",
    "        raw_response, validated_response = self.guard(\n",
    "            openai.ChatCompletion.create,\n",
    "            prompt_params={\"current_code\": self.inspect_methods(self), \"task\": task},\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "        )\n",
    "\n",
    "        return validated_response\n",
    "\n",
    "    def make_api_call(self, task):\n",
    "        prompt = f\"\"\"\n",
    "        The current code looks like this: {self.inspect_methods(self)}\n",
    "\n",
    "        You must accomplish the task set out below:\n",
    "        {task}\n",
    "        \"\"\"\n",
    "\n",
    "        new_message = {\"role\": \"user\", \"content\": prompt}\n",
    "\n",
    "        self.messages.append(new_message)\n",
    "\n",
    "        # Make a call to the GPT-3.5 Turbo API and return the generated code\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                *self.messages,\n",
    "            ],\n",
    "        )\n",
    "        return response\n",
    "\n",
    "    def generate_code_from_response(self, response):\n",
    "        response_message = response.choices[0].message.content\n",
    "        matches = re.findall(r\"```(.*?)```\", response_message, re.DOTALL)\n",
    "        list_code = [match for match in matches]\n",
    "        return list_code\n",
    "\n",
    "    def process_code(self, code):\n",
    "        # Process the returned code and add it to AutonomousLLM\n",
    "        exec(code)\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            # Think of a new feature to add\n",
    "            new_feature = self.think_of_feature()\n",
    "\n",
    "            # Generate code for the new feature\n",
    "            code = f\"\"\"\n",
    "            # Code generation logic for the new feature\n",
    "            {new_feature}\n",
    "            \"\"\"\n",
    "\n",
    "            # Make an API call to GPT-3.5 Turbo\n",
    "            generated_code = self.make_api_call(code)\n",
    "\n",
    "            # Process the returned code\n",
    "            self.process_code(generated_code)\n",
    "\n",
    "            # Utilize the new ability\n",
    "            self.use_new_ability()\n",
    "\n",
    "    def use_new_ability(self):\n",
    "        # Use the newly added ability in your code\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_llm = AutonomousLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = auto_llm.make_api_call(\"I want you to add the ability to extract title from webpages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = auto_llm.make_api_call(\"I want you to send an email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_parsed = literal_eval(res.choices[0].message.content)\n",
    "for name, res in res_parsed.items():\n",
    "    print(name)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, res in res_parsed.items():\n",
    "    print(name)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_to_execute = auto_llm.process_response(res)\n",
    "code_to_execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in code_to_execute:\n",
    "    print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(code_to_execute[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(auto_llm.inspect_methods(auto_llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect.getsource(auto_llm.__dict__['extract_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_llm.process_code(code_to_execute[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = auto_llm.process_code(code_to_execute[2])\n",
    "rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_llm.extract_title(\"https://www.google.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = auto_llm.process_response(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect.getmembers(auto_llm, not inspect.isbuiltin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_builtin(obj):\n",
    "    \"\"\"Check if an object is a built-in function or method.\"\"\"\n",
    "    if isinstance(obj, types.BuiltinFunctionType) or isinstance(obj, types.BuiltinMethodType):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def inspect_methods(obj):\n",
    "    \"\"\"Print the methods and code implementation of an object.\"\"\"\n",
    "    output_string = \"\"\n",
    "\n",
    "    methods = inspect.getmembers(obj, inspect.ismethod)\n",
    "    for name, method in methods:\n",
    "        if not is_builtin(method):\n",
    "            output_string += f\"Method: {name}\\n\"\n",
    "            output_string += inspect.getsource(method) + '\\n\\n'\n",
    "    return output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inspect_methods(auto_llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AutonomousLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dis\n",
    "\n",
    "class MyClass:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "obj = MyClass()\n",
    "\n",
    "# Dynamically add a method using exec\n",
    "exec(\"def new_method(self):\\n    print('This is the dynamically added method')\")\n",
    "\n",
    "# Assign the method to the object\n",
    "setattr(obj, \"new_method\", new_method)\n",
    "\n",
    "# Retrieve the bytecode\n",
    "bytecode = obj.new_method.__code__.co_code\n",
    "\n",
    "# Disassemble the bytecode to get an approximation of the source code\n",
    "disassembly = dis.dis(obj.new_method.__code__)\n",
    "\n",
    "# Print the disassembled code\n",
    "print(disassembly)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
